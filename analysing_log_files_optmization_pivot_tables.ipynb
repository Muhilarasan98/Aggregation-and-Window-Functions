{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b592d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "spark = SparkSession. \\\n",
    "builder. \\\n",
    "config(\"spark.sql.warehouse.dir\", f\"/user/{username}/warehouse\"). \\\n",
    "enableHiveSupport(). \\\n",
    "master('yarn'). \\\n",
    "getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9e66d884",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_data = [(\"DEBUG\",\"2014-6-22 21:30:49\"),\n",
    "(\"WARN\",\"2013-12-6 17:54:15\"),\n",
    "(\"DEBUG\",\"2017-1-12 10:47:02\"),\n",
    "(\"DEBUG\",\"2016-6-25 11:06:42\"),\n",
    "(\"ERROR\",\"2015-6-28 19:25:05\"),\n",
    "(\"DEBUG\",\"2012-6-24 01:06:37\"),\n",
    "(\"INFO\",\"2014-12-9 09:53:54\"),\n",
    "(\"DEBUG\",\"2015-11-8 19:20:08\"),\n",
    "(\"INFO\",\"2017-12-21 18:34:18\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a52c0238",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = spark.createDataFrame(logs_data).toDF(\"loglevel\",\"logtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "def11484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|loglevel|            logtime|\n",
      "+--------+-------------------+\n",
      "|   DEBUG| 2014-6-22 21:30:49|\n",
      "|    WARN| 2013-12-6 17:54:15|\n",
      "|   DEBUG| 2017-1-12 10:47:02|\n",
      "|   DEBUG| 2016-6-25 11:06:42|\n",
      "|   ERROR| 2015-6-28 19:25:05|\n",
      "|   DEBUG| 2012-6-24 01:06:37|\n",
      "|    INFO| 2014-12-9 09:53:54|\n",
      "|   DEBUG| 2015-11-8 19:20:08|\n",
      "|    INFO|2017-12-21 18:34:18|\n",
      "+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "478de7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loglevel: string (nullable = true)\n",
      " |-- logtime: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "bdd51b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5b703e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_logdf = log_df.withColumn(\"logtime\",to_timestamp(\"logtime\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0bc476b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>loglevel</th><th>logtime</th></tr>\n",
       "<tr><td>DEBUG</td><td>2014-06-22 21:30:49</td></tr>\n",
       "<tr><td>WARN</td><td>2013-12-06 17:54:15</td></tr>\n",
       "<tr><td>DEBUG</td><td>2017-01-12 10:47:02</td></tr>\n",
       "<tr><td>DEBUG</td><td>2016-06-25 11:06:42</td></tr>\n",
       "<tr><td>ERROR</td><td>2015-06-28 19:25:05</td></tr>\n",
       "<tr><td>DEBUG</td><td>2012-06-24 01:06:37</td></tr>\n",
       "<tr><td>INFO</td><td>2014-12-09 09:53:54</td></tr>\n",
       "<tr><td>DEBUG</td><td>2015-11-08 19:20:08</td></tr>\n",
       "<tr><td>INFO</td><td>2017-12-21 18:34:18</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+-------------------+\n",
       "|loglevel|            logtime|\n",
       "+--------+-------------------+\n",
       "|   DEBUG|2014-06-22 21:30:49|\n",
       "|    WARN|2013-12-06 17:54:15|\n",
       "|   DEBUG|2017-01-12 10:47:02|\n",
       "|   DEBUG|2016-06-25 11:06:42|\n",
       "|   ERROR|2015-06-28 19:25:05|\n",
       "|   DEBUG|2012-06-24 01:06:37|\n",
       "|    INFO|2014-12-09 09:53:54|\n",
       "|   DEBUG|2015-11-08 19:20:08|\n",
       "|    INFO|2017-12-21 18:34:18|\n",
       "+--------+-------------------+"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_logdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bf4a8601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|loglevel|            logtime|\n",
      "+--------+-------------------+\n",
      "|   DEBUG|2014-06-22 21:30:49|\n",
      "|    WARN|2013-12-06 17:54:15|\n",
      "|   DEBUG|2017-01-12 10:47:02|\n",
      "|   DEBUG|2016-06-25 11:06:42|\n",
      "|   ERROR|2015-06-28 19:25:05|\n",
      "|   DEBUG|2012-06-24 01:06:37|\n",
      "|    INFO|2014-12-09 09:53:54|\n",
      "|   DEBUG|2015-11-08 19:20:08|\n",
      "|    INFO|2017-12-21 18:34:18|\n",
      "+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_logdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0a61a073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loglevel: string (nullable = true)\n",
      " |-- logtime: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_logdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7b6b5b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_logdf.createOrReplaceTempView(\"serverlogs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "af22c6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>loglevel</th><th>logtime</th></tr>\n",
       "<tr><td>DEBUG</td><td>2014-06-22 21:30:49</td></tr>\n",
       "<tr><td>WARN</td><td>2013-12-06 17:54:15</td></tr>\n",
       "<tr><td>DEBUG</td><td>2017-01-12 10:47:02</td></tr>\n",
       "<tr><td>DEBUG</td><td>2016-06-25 11:06:42</td></tr>\n",
       "<tr><td>ERROR</td><td>2015-06-28 19:25:05</td></tr>\n",
       "<tr><td>DEBUG</td><td>2012-06-24 01:06:37</td></tr>\n",
       "<tr><td>INFO</td><td>2014-12-09 09:53:54</td></tr>\n",
       "<tr><td>DEBUG</td><td>2015-11-08 19:20:08</td></tr>\n",
       "<tr><td>INFO</td><td>2017-12-21 18:34:18</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+-------------------+\n",
       "|loglevel|            logtime|\n",
       "+--------+-------------------+\n",
       "|   DEBUG|2014-06-22 21:30:49|\n",
       "|    WARN|2013-12-06 17:54:15|\n",
       "|   DEBUG|2017-01-12 10:47:02|\n",
       "|   DEBUG|2016-06-25 11:06:42|\n",
       "|   ERROR|2015-06-28 19:25:05|\n",
       "|   DEBUG|2012-06-24 01:06:37|\n",
       "|    INFO|2014-12-09 09:53:54|\n",
       "|   DEBUG|2015-11-08 19:20:08|\n",
       "|    INFO|2017-12-21 18:34:18|\n",
       "+--------+-------------------+"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from serverlogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6be28c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|loglevel|   month|\n",
      "+--------+--------+\n",
      "|   DEBUG|    June|\n",
      "|    WARN|December|\n",
      "|   DEBUG| January|\n",
      "|   DEBUG|    June|\n",
      "|   ERROR|    June|\n",
      "|   DEBUG|    June|\n",
      "|    INFO|December|\n",
      "|   DEBUG|November|\n",
      "|    INFO|December|\n",
      "+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel, date_format(logtime, 'MMMM') as month from serverlogs\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "efe41c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|loglevel|month|\n",
      "+--------+-----+\n",
      "|   DEBUG|   06|\n",
      "|    WARN|   12|\n",
      "|   DEBUG|   01|\n",
      "|   DEBUG|   06|\n",
      "|   ERROR|   06|\n",
      "|   DEBUG|   06|\n",
      "|    INFO|   12|\n",
      "|   DEBUG|   11|\n",
      "|    INFO|   12|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel, date_format(logtime, 'MM') as month from serverlogs\").show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "367e48d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+\n",
      "|loglevel|day|\n",
      "+--------+---+\n",
      "|   DEBUG| 22|\n",
      "|    WARN| 06|\n",
      "|   DEBUG| 12|\n",
      "|   DEBUG| 25|\n",
      "|   ERROR| 28|\n",
      "|   DEBUG| 24|\n",
      "|    INFO| 09|\n",
      "|   DEBUG| 08|\n",
      "|    INFO| 21|\n",
      "+--------+---+\n",
      "\n",
      "+--------+-----+\n",
      "|loglevel|month|\n",
      "+--------+-----+\n",
      "|   DEBUG| 2014|\n",
      "|    WARN| 2013|\n",
      "|   DEBUG| 2017|\n",
      "|   DEBUG| 2016|\n",
      "|   ERROR| 2015|\n",
      "|   DEBUG| 2012|\n",
      "|    INFO| 2014|\n",
      "|   DEBUG| 2015|\n",
      "|    INFO| 2017|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel, date_format(logtime, 'dd') as day from serverlogs\").show()\n",
    "spark.sql(\"select loglevel, date_format(logtime, 'yyyy') as month from serverlogs\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9cbf8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ae0a772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logschema = \"loglevel string, logtime timestamp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3bd118c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = spark.read \\\n",
    ".format(\"csv\") \\\n",
    ".schema(logschema) \\\n",
    ".load(\"/public/trendytech/datasets/logdata1m.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "176289cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|loglevel|            logtime|\n",
      "+--------+-------------------+\n",
      "|    INFO|2015-08-08 20:49:22|\n",
      "|    WARN|2015-01-14 20:05:00|\n",
      "|    INFO|2017-06-14 00:08:35|\n",
      "|    INFO|2016-01-18 11:50:14|\n",
      "|   DEBUG|2017-07-01 12:55:02|\n",
      "|    INFO|2014-02-26 12:34:21|\n",
      "|    INFO|2015-07-12 11:13:47|\n",
      "|    INFO|2017-04-15 01:20:18|\n",
      "|   DEBUG|2016-11-02 20:19:23|\n",
      "|    INFO|2012-08-20 10:09:44|\n",
      "|   DEBUG|2014-04-22 21:30:49|\n",
      "|    WARN|2013-12-06 17:54:15|\n",
      "|   DEBUG|2017-01-12 10:47:02|\n",
      "|   DEBUG|2016-06-25 11:06:42|\n",
      "|   ERROR|2015-06-28 19:25:05|\n",
      "|   DEBUG|2012-06-24 01:06:37|\n",
      "|    INFO|2014-12-09 09:53:54|\n",
      "|   DEBUG|2015-11-08 19:20:08|\n",
      "|    INFO|2017-07-21 18:34:18|\n",
      "|   DEBUG|2014-12-26 06:38:42|\n",
      "+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "289d9d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "aee4d30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loglevel: string (nullable = true)\n",
      " |-- logtime: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "0f4b068a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|loglevel|            logtime|\n",
      "+--------+-------------------+\n",
      "|    INFO|2015-08-08 20:49:22|\n",
      "|    WARN|2015-01-14 20:05:00|\n",
      "|    INFO|2017-06-14 00:08:35|\n",
      "|    INFO|2016-01-18 11:50:14|\n",
      "|   DEBUG|2017-07-01 12:55:02|\n",
      "|    INFO|2014-02-26 12:34:21|\n",
      "|    INFO|2015-07-12 11:13:47|\n",
      "|    INFO|2017-04-15 01:20:18|\n",
      "|   DEBUG|2016-11-02 20:19:23|\n",
      "|    INFO|2012-08-20 10:09:44|\n",
      "|   DEBUG|2014-04-22 21:30:49|\n",
      "|    WARN|2013-12-06 17:54:15|\n",
      "|   DEBUG|2017-01-12 10:47:02|\n",
      "|   DEBUG|2016-06-25 11:06:42|\n",
      "|   ERROR|2015-06-28 19:25:05|\n",
      "|   DEBUG|2012-06-24 01:06:37|\n",
      "|    INFO|2014-12-09 09:53:54|\n",
      "|   DEBUG|2015-11-08 19:20:08|\n",
      "|    INFO|2017-07-21 18:34:18|\n",
      "|   DEBUG|2014-12-26 06:38:42|\n",
      "+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "433b8109",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df.createOrReplaceTempView(\"serverlogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f28147ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|loglevel|            logtime|\n",
      "+--------+-------------------+\n",
      "|    INFO|2015-08-08 20:49:22|\n",
      "|    WARN|2015-01-14 20:05:00|\n",
      "|    INFO|2017-06-14 00:08:35|\n",
      "|    INFO|2016-01-18 11:50:14|\n",
      "|   DEBUG|2017-07-01 12:55:02|\n",
      "|    INFO|2014-02-26 12:34:21|\n",
      "|    INFO|2015-07-12 11:13:47|\n",
      "|    INFO|2017-04-15 01:20:18|\n",
      "|   DEBUG|2016-11-02 20:19:23|\n",
      "|    INFO|2012-08-20 10:09:44|\n",
      "|   DEBUG|2014-04-22 21:30:49|\n",
      "|    WARN|2013-12-06 17:54:15|\n",
      "|   DEBUG|2017-01-12 10:47:02|\n",
      "|   DEBUG|2016-06-25 11:06:42|\n",
      "|   ERROR|2015-06-28 19:25:05|\n",
      "|   DEBUG|2012-06-24 01:06:37|\n",
      "|    INFO|2014-12-09 09:53:54|\n",
      "|   DEBUG|2015-11-08 19:20:08|\n",
      "|    INFO|2017-07-21 18:34:18|\n",
      "|   DEBUG|2014-12-26 06:38:42|\n",
      "+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from serverlogs\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b68844b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------------+\n",
      "|loglevel|    month|total_occurence|\n",
      "+--------+---------+---------------+\n",
      "|    WARN|     June|           8191|\n",
      "|    INFO|     June|          29143|\n",
      "|   ERROR| November|           3389|\n",
      "|   FATAL|  January|             94|\n",
      "|    WARN| December|           8328|\n",
      "|    WARN|    March|           8165|\n",
      "|   DEBUG|     July|          42085|\n",
      "|   ERROR|    April|           4107|\n",
      "|   ERROR|  January|           4054|\n",
      "|   FATAL|September|             81|\n",
      "|   FATAL|    April|             83|\n",
      "|    INFO|September|          29038|\n",
      "|   FATAL| November|          16797|\n",
      "|   FATAL|  October|             92|\n",
      "|    INFO| February|          28983|\n",
      "|    WARN|    April|           8277|\n",
      "|   DEBUG| December|          41749|\n",
      "|   FATAL| December|             94|\n",
      "|    WARN|      May|           8403|\n",
      "|   ERROR|     June|           4059|\n",
      "+--------+---------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel, date_format(logtime, 'MMMM') as month, count(*) as total_occurence from serverlogs group by loglevel, month\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b4dd4ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+---------------+\n",
      "|loglevel|year|total_occurence|\n",
      "+--------+----+---------------+\n",
      "|    WARN|2012|          16374|\n",
      "|   ERROR|2013|           7968|\n",
      "|   DEBUG|2014|          82386|\n",
      "|   FATAL|2017|           2924|\n",
      "|   FATAL|2012|           2925|\n",
      "|    INFO|2012|          56964|\n",
      "|   FATAL|2013|           2991|\n",
      "|   DEBUG|2012|          81914|\n",
      "|   ERROR|2012|           7860|\n",
      "|   ERROR|2014|           8095|\n",
      "|    WARN|2014|          16267|\n",
      "|   DEBUG|2016|          82581|\n",
      "|   FATAL|2014|           2920|\n",
      "|    INFO|2013|          57206|\n",
      "|    INFO|2017|          56805|\n",
      "|   ERROR|2015|           8095|\n",
      "|    INFO|2016|          57254|\n",
      "|    WARN|2013|          16098|\n",
      "|    INFO|2015|          57494|\n",
      "|   DEBUG|2017|          81858|\n",
      "+--------+----+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select loglevel, date_format(logtime, 'yyyy') as year, \n",
    "count(*) as total_occurence from serverlogs group by loglevel, year\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "3bf1be14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+---------------+\n",
      "|loglevel|day|total_occurence|\n",
      "+--------+---+---------------+\n",
      "|   ERROR| 18|           1694|\n",
      "|   DEBUG| 15|          17587|\n",
      "|   FATAL| 24|            610|\n",
      "|    INFO| 15|          12218|\n",
      "|   FATAL| 19|            615|\n",
      "|   ERROR| 06|           1747|\n",
      "|   ERROR| 19|           1694|\n",
      "|   DEBUG| 14|          17841|\n",
      "|    INFO| 02|          12477|\n",
      "|    WARN| 15|           3551|\n",
      "|   ERROR| 13|           1699|\n",
      "|   ERROR| 09|           1700|\n",
      "|   DEBUG| 03|          17587|\n",
      "|    WARN| 14|           3456|\n",
      "|   ERROR| 21|           1770|\n",
      "|   FATAL| 22|            636|\n",
      "|    INFO| 12|          12372|\n",
      "|   ERROR| 17|           1753|\n",
      "|   ERROR| 24|           1685|\n",
      "|   DEBUG| 01|          17483|\n",
      "+--------+---+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel, date_format(logtime, 'dd') as day, count(*) as total_occurence from serverlogs group by loglevel, day\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7d0883c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+------------+---------------+\n",
      "|loglevel|   month|Month_number|total_occurence|\n",
      "+--------+--------+------------+---------------+\n",
      "|    WARN| January|           1|           8217|\n",
      "|   DEBUG| January|           1|          41961|\n",
      "|   FATAL| January|           1|             94|\n",
      "|    INFO| January|           1|          29119|\n",
      "|   ERROR| January|           1|           4054|\n",
      "|    INFO|February|           2|          28983|\n",
      "|   DEBUG|February|           2|          41734|\n",
      "|    WARN|February|           2|           8266|\n",
      "|   ERROR|February|           2|           4013|\n",
      "|   FATAL|February|           2|             72|\n",
      "|    INFO|   March|           3|          29095|\n",
      "|   FATAL|   March|           3|             70|\n",
      "|   DEBUG|   March|           3|          41652|\n",
      "|    WARN|   March|           3|           8165|\n",
      "|   ERROR|   March|           3|           4122|\n",
      "|   DEBUG|   April|           4|          41869|\n",
      "|   FATAL|   April|           4|             83|\n",
      "|    INFO|   April|           4|          29302|\n",
      "|    WARN|   April|           4|           8277|\n",
      "|   ERROR|   April|           4|           4107|\n",
      "+--------+--------+------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select loglevel, date_format(logtime, 'MMMM') as month, int(date_format(logtime, 'M')) as Month_number,\n",
    "count(*) as total_occurence from serverlogs group by loglevel, month, Month_number order by Month_number\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "80ea0d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = spark.sql(\"select loglevel, date_format(logtime, 'MMMM') as month, first(date_format(logtime, 'MM')) as month_num, count(*) as total_occurences from serverlogs group by loglevel,month order by month_num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "52ff4fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------+----------------+\n",
      "|loglevel|   month|month_num|total_occurences|\n",
      "+--------+--------+---------+----------------+\n",
      "|   DEBUG| January|       01|           41961|\n",
      "|   FATAL| January|       01|              94|\n",
      "|    INFO| January|       01|           29119|\n",
      "|   ERROR| January|       01|            4054|\n",
      "|    WARN| January|       01|            8217|\n",
      "|    WARN|February|       02|            8266|\n",
      "|   ERROR|February|       02|            4013|\n",
      "|   DEBUG|February|       02|           41734|\n",
      "|   FATAL|February|       02|              72|\n",
      "|    INFO|February|       02|           28983|\n",
      "|   ERROR|   March|       03|            4122|\n",
      "|    WARN|   March|       03|            8165|\n",
      "|    INFO|   March|       03|           29095|\n",
      "|   DEBUG|   March|       03|           41652|\n",
      "|   FATAL|   March|       03|              70|\n",
      "|   ERROR|   April|       04|            4107|\n",
      "|    WARN|   April|       04|            8277|\n",
      "|   FATAL|   April|       04|              83|\n",
      "|    INFO|   April|       04|           29302|\n",
      "|   DEBUG|   April|       04|           41869|\n",
      "+--------+--------+---------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "453809b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = result_df.drop('month_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0db818f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+----------------+\n",
      "|loglevel|   month|total_occurences|\n",
      "+--------+--------+----------------+\n",
      "|   FATAL| January|              94|\n",
      "|    INFO| January|           29119|\n",
      "|   ERROR| January|            4054|\n",
      "|   DEBUG| January|           41961|\n",
      "|    WARN| January|            8217|\n",
      "|   FATAL|February|              72|\n",
      "|    WARN|February|            8266|\n",
      "|   ERROR|February|            4013|\n",
      "|   DEBUG|February|           41734|\n",
      "|    INFO|February|           28983|\n",
      "|   FATAL|   March|              70|\n",
      "|    WARN|   March|            8165|\n",
      "|   DEBUG|   March|           41652|\n",
      "|   ERROR|   March|            4122|\n",
      "|    INFO|   March|           29095|\n",
      "|   ERROR|   April|            4107|\n",
      "|    WARN|   April|            8277|\n",
      "|    INFO|   April|           29302|\n",
      "|   DEBUG|   April|           41869|\n",
      "|   FATAL|   April|              83|\n",
      "+--------+--------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "28c762e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|loglevel|   month|\n",
      "+--------+--------+\n",
      "|    INFO|  August|\n",
      "|    WARN| January|\n",
      "|    INFO|    June|\n",
      "|    INFO| January|\n",
      "|   DEBUG|    July|\n",
      "|    INFO|February|\n",
      "|    INFO|    July|\n",
      "|    INFO|   April|\n",
      "|   DEBUG|November|\n",
      "|    INFO|  August|\n",
      "|   DEBUG|   April|\n",
      "|    WARN|December|\n",
      "|   DEBUG| January|\n",
      "|   DEBUG|    June|\n",
      "|   ERROR|    June|\n",
      "|   DEBUG|    June|\n",
      "|    INFO|December|\n",
      "|   DEBUG|November|\n",
      "|    INFO|    July|\n",
      "|   DEBUG|December|\n",
      "+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel, date_format(logtime, 'MMMM') as month from serverlogs\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "3a2f6f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|loglevel|   month|\n",
      "+--------+--------+\n",
      "|    INFO|  August|\n",
      "|    WARN| January|\n",
      "|    INFO|    June|\n",
      "|    INFO| January|\n",
      "|   DEBUG|    July|\n",
      "|    INFO|February|\n",
      "|    INFO|    July|\n",
      "|    INFO|   April|\n",
      "|   DEBUG|November|\n",
      "|    INFO|  August|\n",
      "|   DEBUG|   April|\n",
      "|    WARN|December|\n",
      "|   DEBUG| January|\n",
      "|   DEBUG|    June|\n",
      "|   ERROR|    June|\n",
      "|   DEBUG|    June|\n",
      "|    INFO|December|\n",
      "|   DEBUG|November|\n",
      "|    INFO|    July|\n",
      "|   DEBUG|December|\n",
      "+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel, date_format(logtime, 'MMMM') as month from serverlogs\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "18e6308f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+------+--------+--------+-------+-----+-----+-----+-----+--------+-------+---------+\n",
      "|loglevel|April|August|December|February|January| July| June|March|  May|November|October|September|\n",
      "+--------+-----+------+--------+--------+-------+-----+-----+-----+-----+--------+-------+---------+\n",
      "|    INFO|29302| 28993|   28874|   28983|  29119|29300|29143|29095|28900|   23301|  29018|    29038|\n",
      "|   ERROR| 4107|  3987|    4106|    4013|   4054| 3976| 4059| 4122| 4086|    3389|   4040|     4161|\n",
      "|    WARN| 8277|  8381|    8328|    8266|   8217| 8222| 8191| 8165| 8403|    6616|   8226|     8352|\n",
      "|   FATAL|   83|    80|      94|      72|     94|   98|   78|   70|   60|   16797|     92|       81|\n",
      "|   DEBUG|41869| 42147|   41749|   41734|  41961|42085|41774|41652|41785|   33366|  41936|    41433|\n",
      "+--------+-----+------+--------+--------+-------+-----+-----+-----+-----+--------+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel, date_format(logtime, 'MMMM') as month from serverlogs\").groupBy('loglevel').pivot('Month').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9a267ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+-----+-----+-----+-----+-----+\n",
      "|loglevel| 2012| 2013| 2014| 2015| 2016| 2017|\n",
      "+--------+-----+-----+-----+-----+-----+-----+\n",
      "|    INFO|56964|57206|57343|57494|57254|56805|\n",
      "|   ERROR| 7860| 7968| 8095| 8095| 8050| 8032|\n",
      "|    WARN|16374|16098|16267|16155|16426|16324|\n",
      "|   FATAL| 2925| 2991| 2920| 2974| 2965| 2924|\n",
      "|   DEBUG|81914|82444|82386|82308|82581|81858|\n",
      "+--------+-----+-----+-----+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel, date_format(logtime, 'yyyy') as year from serverlogs\").groupBy('loglevel').pivot('year').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d4f4f8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
      "|loglevel|   01|   02|   03|   04|   05|   06|   07|   08|   09|   10|   11|   12|   13|   14|   15|   16|   17|   18|   19|   20|   21|   22|   23|   24|   25|   26|   27|   28|\n",
      "+--------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
      "|    INFO|12317|12477|12091|12436|12237|12221|12385|12172|12468|12080|12276|12372|12640|12252|12218|12276|12073|12295|12158|12015|12302|12003|12105|12431|12286|12148|12171|12161|\n",
      "|   ERROR| 1695| 1737| 1771| 1771| 1763| 1747| 1735| 1648| 1700| 1668| 1660| 1712| 1699| 1783| 1750| 1777| 1753| 1694| 1694| 1636| 1770| 1718| 1701| 1685| 1777| 1689| 1664| 1703|\n",
      "|    WARN| 3382| 3511| 3412| 3528| 3541| 3460| 3584| 3541| 3412| 3464| 3415| 3424| 3546| 3456| 3551| 3478| 3545| 3493| 3506| 3601| 3466| 3408| 3530| 3446| 3510| 3463| 3436| 3535|\n",
      "|   DEBUG|17483|17625|17587|17658|17672|17704|17648|17691|17578|17605|17528|17547|17562|17841|17587|17577|17975|17593|17655|17464|17361|17780|17555|17574|17649|17731|17584|17677|\n",
      "|   FATAL|  629|  621|  650|  627|  632|  637|  635|  591|  633|  638|  618|  635|  642|  679|  649|  615|  646|  666|  615|  609|  598|  636|  654|  610|  615|  648|  637|  634|\n",
      "+--------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel, date_format(logtime, 'dd') as day from serverlogs\").groupBy('loglevel').pivot('day').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "95684226",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8f399e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
